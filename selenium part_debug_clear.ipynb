{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###코드 통합\n",
    "\n",
    "################################################################\n",
    "\n",
    "# 1. 라이브러리 선언\n",
    "# 2. 전역변수 선선\n",
    "# 3. 공용 메소드 설정\n",
    "# 4. 클래스 선언부\n",
    "# 4-1. 중고차 크롤링 선언\n",
    "# 4-1-1. kcar 크롤링 선언\n",
    "# 4-2. 신차 크롤링 선언\n",
    "# 5. main 작동부\n",
    "\n",
    "#################################################################\n",
    "\n",
    "# 1. 라이브러리 선언\n",
    "\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests, bs4\n",
    "import csv\n",
    "\n",
    "# 2. 전역변수 정리\n",
    "\n",
    "# 3. 공용 메소드 선언\n",
    "# 3-1. selenium 시동\n",
    "\n",
    "def startSelenimum():\n",
    "    \n",
    "    driverpath = \"./chromedriver.exe\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('headless')\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    options.add_argument('disable-gpu')\n",
    "\n",
    "    # 웹드라이버 정의(위 headless 사용시 필수)\n",
    "\n",
    "    driver = webdriver.Chrome(driverpath, options=options)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def trigerSelenium(driver,url):\n",
    "\n",
    "    driver.get(url)\n",
    "    print(\"페이지 생성\")\n",
    "\n",
    "# 3-2. selenium parser\n",
    "def getHtmlWithSelenium(driver_tool, targetUrl):\n",
    "\n",
    "    driver_tool.get(targetUrl)\n",
    "\n",
    "    time.sleep(0.3)\n",
    "\n",
    "    html = driver_tool.page_source\n",
    "\n",
    "    bs = bs4.BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "    return bs\n",
    "# 3-3. request parser\n",
    "def getHtmlWithRequests(targetUrl, sleepSeconds):\n",
    "\n",
    "    response = requests.get(url = targetUrl)\n",
    "\n",
    "    time.sleep(sleepSeconds)\n",
    "\n",
    "    response.encoding = \"utf-8\"\n",
    "\n",
    "    html = response.text\n",
    "\n",
    "    bs = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    return bs\n",
    "\n",
    "\n",
    "class getURL:\n",
    "    \"\"\"\"Super Class\"\"\"\n",
    "    def __init__(self, baseurl):\n",
    "        self.baseurl = baseurl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##본 코드는 kcar 한정코드\n",
    "# 4-1-1. kcarurl 코드 부분\n",
    "class kCar_getURL(getURL):\n",
    "    \"\"\"sub Class\"\"\"\n",
    "    def __init__(self, baseurl):\n",
    "\n",
    "\n",
    "        self.baseurl = baseurl\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def option(driver):\n",
    "\n",
    "        cntMainXpath = '//*[@id=\"filterSearch\"]/section[2]/div[2]/div[3]/div[2]/b'\n",
    "        cntSubXpath = '//*[@id=\"filterSearch\"]/section[2]/div[2]/div[3]/div[3]/div/ul/li[4]'\n",
    "\n",
    "\n",
    "        cntMain = driver.find_element_by_xpath(cntMainXpath)\n",
    "        cntSub = driver.find_element_by_xpath(cntSubXpath)\n",
    "\n",
    "        cntMain.click()\n",
    "        time.sleep(delaychecker)\n",
    "        cntSub.click()\n",
    "\n",
    "    def collectUrl(delaychecker, driver):\n",
    "\n",
    "        page = 0\n",
    "        escape = 1\n",
    "        print(\"페이지 조건 등록\")\n",
    "        time.sleep(delaychecker)\n",
    "\n",
    "        html = driver.page_source\n",
    "        bs = bs4.BeautifulSoup(html, 'html.parser')\n",
    "        print(\"페이지 긁기 완료\")\n",
    "        startTime = time.time()\n",
    "\n",
    "        urlList = []\n",
    "        print(\"반복문 전까지 완료\")\n",
    "        while (escape == 1):\n",
    "            for i in range(0, 10):\n",
    "                try:\n",
    "\n",
    "                    page += 1\n",
    "                    pageXpath = '//*[@id=\"filterSearch\"]/section[2]/div[5]/div/button[' + str(i + 1) + ']'\n",
    "                    driver.find_element_by_xpath(pageXpath).click()\n",
    "                    time.sleep(delaychecker)\n",
    "                    html = driver.page_source\n",
    "                    bs = bs4.BeautifulSoup(html, 'html.parser')\n",
    "                    buttonTags = bs.find(name = \"ol\").findAll(name = \"button\", attrs = {\"class\" : \"btn_compare\"})\n",
    "\n",
    "\n",
    "                    for eachButtonTag in buttonTags:\n",
    "\n",
    "                        addUrl = eachButtonTag['data-car-cd']\n",
    "                        eachUrl = baseUrl + addUrl\n",
    "                        urlList.append(eachUrl)\n",
    "\n",
    "                except:\n",
    "\n",
    "                    escape = 0\n",
    "\n",
    "            if (page % 10 == 0):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    nextIndexXpath = '//*[@id=\"filterSearch\"]/section[2]/div[5]/button[2]'\n",
    "                    driver.find_element_by_xpath(nextIndexXpath).click()\n",
    "                    time.sleep(delaychecker)\n",
    "\n",
    "                except:\n",
    "\n",
    "                    escape = 0\n",
    "\n",
    "        endTime = time.time()\n",
    "        doneTime = endTime - startTime\n",
    "        print(\"총 소요시간\" + doneTime)\n",
    "        print(\"총 URL은 \" + len(urlList))\n",
    "\n",
    "        linkDataFrame = pd.DataFrame(urlList, columns = ['url'])\n",
    "        linkDataFrame.to_csv(\"./UrlList.csv\", encoding='ms949', index=False)\n",
    "        urlList = urlDataFrame['url'].tolist()\n",
    "\n",
    "        return urlList\n",
    "\n",
    "# 5. main part\n",
    "try:\n",
    "    delaychecker = 0.3\n",
    "    kCarUrl = \"https://www.kcar.com/car/search/car_search_list.do\"\n",
    "    seldriver = startSelenimum()\n",
    "    print(\"드라이버 생성\")\n",
    "    trigerSelenium(seldriver, kCarUrl)\n",
    "    print(\"셀레니움 가동\")\n",
    "    kCarpage = kCar_getURL(kCarUrl)\n",
    "    print(\"페이지 정상작동\")\n",
    "    \n",
    "   \n",
    "    #kcar객체선언\n",
    "\n",
    "#     #kcar의 페이지 옵션(60페이지 검색 클릭)\n",
    "#     kCarpage.option(seldriver)\n",
    "\n",
    "except:\n",
    "    print(\"페이지 불러오기 오류\")\n",
    "\n",
    "\n",
    "\n",
    "#상세정보url 리스트 정리\n",
    "\n",
    "kCarUrlList = kCarpage.collectUrl(delaychecker, seldriver)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 원본 main 코드 부분\n",
    "\n",
    "containingList =[]\n",
    "startTime = time.time()\n",
    "retryTargetUrlList = []\n",
    "totalList=[]\n",
    "\n",
    "\n",
    "for targetUrl in kCarUrlList:\n",
    "    try:\n",
    "        containingList = []\n",
    "        request_bs = getHtmlWithRequests(targetUrl, delaychecker)\n",
    "        kCar_getInfo(request_bs, containingList)\n",
    "        totalList.append(containingList)\n",
    "        \n",
    "    except:\n",
    "        retryTargetUrlList.append(targetUrl)\n",
    "        print(\"request 페이지 정보 parsing 실패\")\n",
    "        print(targetUrl)\n",
    "endTime = time.time()\n",
    "doneTime = endTime - startTime\n",
    "print(\"request parsing time\"+ doneTime)\n",
    "\n",
    "result = pd.DataFrame(totalList)\n",
    "\n",
    "result.columns = ['제품명', '사고유무', '중고차 가격', '차량번호', '배기량', '연식', '색상', '주행거리', '변속기', '연료', '차종', '압류/저당', '구동방식', '인승', '제시번호']\n",
    "\n",
    "result.to_csv('./UsedCarData.csv', encoding = 'ms949', index = False)\n",
    "\n",
    "retryTargetUrlDataFrame = pd.DataFrame(retryTargetUrlList)\n",
    "retryTargetUrlDataFrame.columns = [\"Url\"]\n",
    "retryTargetUrlDataFrame.to_csv('./retryTargetUrl.csv', encoding = 'ms949', index = False)\n",
    "\n",
    "\n",
    "retryTargetUrlDataFrame = pd.read_csv(\"./retryTargetUrl.csv\", encoding = 'ms949')\n",
    "retryTargetUrlList = retryTargetUrlDataFrame['Url'].tolist()\n",
    "\n",
    "errorURL = []\n",
    "reTotalList=[]\n",
    "startTime = time.time()\n",
    "for eachRetryUrl in retryTargetUrlList:#여기를 retryTargetUrl로 변경해야함\n",
    "\n",
    "    try:\n",
    "        containingList = []\n",
    "        selenium_bs = getHtmlWithSelenium(driver_tool, eachRetryUrl)\n",
    "        containingList = kCar_getInfo(selenium_bs, containingList)\n",
    "        reTotalList.append(eachRetryUrl)\n",
    "\n",
    "    except:\n",
    "        errorURL.append(targetUrl)\n",
    "        print(\"selenium 페이지 정보 parsing 실패\")\n",
    "        print(targetUrl)\n",
    "\n",
    "endTime = time.time()\n",
    "doneTime = endTime - startTime\n",
    "print(\"selenium parsing time\"+ doneTime)\n",
    "\n",
    "\n",
    "\n",
    "reResult = pd.DataFrame(reTotalList)#없는 변수, 해당부분을 containinglist로 변경필\n",
    "\n",
    "reResult.columns = ['제품명', '사고유무', '중고차 가격', '차량번호', '배기량', '연식', '색상', '주행거리', '변속기', '연료', '차종', '압류/저당', '구동방식', '인승', '제시번호']\n",
    "\n",
    "finaldata = pd.concat([result, reResult])\n",
    "\n",
    "finaldata.to_csv(\"./filename.csv\", mode='w')\n",
    "\n",
    "\n",
    "#현제 셀레니움과 리퀘스트 관련하여 리스트로 붙여넣고 있음, for문활용하여 dataframe 형태로 변경필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
